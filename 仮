import os
import cv2
import numpy as np
import sys
import shutil
import random
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def confirm_and_reset_output_dir(output_dir):
    if os.path.exists(output_dir):
        while True:
            response = input(f"Warning: '{output_dir}' already exists and contains data. Do you want to reset it? (yes/no): ").strip().lower()
            if response in ['yes', 'y']:
                print("Deleting processed_data folder...")
                shutil.rmtree(output_dir)  # フォルダ削除
                while os.path.exists(output_dir):  # 完全に削除されたことを確認
                    pass
                print("Deletion complete. Proceeding with further processing...")
                os.makedirs(output_dir, exist_ok=True)  # 新たに作成
                break
            elif response in ['no', 'n']:
                print("Aborting process.")
                sys.exit(0)
            else:
                print("Invalid input. Please enter 'yes' or 'no'.")

    else:
        os.makedirs(output_dir, exist_ok=True)

def organize_and_resize_with_blurred_background(input_dir, output_dir, no_face_dir, target_size=(224, 224)):
    cascades_dir = os.path.join(os.path.dirname(__file__), "cascades")
    model_file = os.path.join(cascades_dir, "deploy.prototxt")
    weights_file = os.path.join(cascades_dir, "res10_300x300_ssd_iter_140000.caffemodel")
    net = cv2.dnn.readNetFromCaffe(model_file, weights_file)

    os.makedirs(no_face_dir, exist_ok=True)

    total_images = sum(len([f for f in files if f.lower().endswith(('jpg', 'jpeg', 'png'))]) for _, _, files in os.walk(input_dir))
    processed_images = 0
    no_face_count = 0

    for class_name in os.listdir(input_dir):
        class_path = os.path.join(input_dir, class_name)
        if not os.path.isdir(class_path) or class_name == "~logs":
            continue

        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            if not img_name.lower().endswith(('jpg', 'jpeg', 'png')):
                continue
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path)

            if img is None:
                print(f"Warning: Unable to read image {img_path}")
                continue

            (h, w) = img.shape[:2]
            blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
            net.setInput(blob)
            detections = net.forward()

            max_area = 0
            face_box = None
            for i in range(detections.shape[2]):
                confidence = detections[0, 0, i, 2]
                if confidence > 0.5:
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    (x1, y1, x2, y2) = box.astype("int")
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area:
                        max_area = area
                        face_box = (x1, y1, x2, y2)

            if face_box is not None:
                processed_img = blur_background(img, face_box, target_size)
                output_path = os.path.join(output_class_path, img_name)
                cv2.imwrite(output_path, processed_img)
            else:
                no_face_count += 1
                no_face_path = os.path.join(no_face_dir, img_name)
                cv2.imwrite(no_face_path, img)

            processed_images += 1
            progress = f"Processed: {processed_images}/{total_images} ({(processed_images / total_images) * 100:.2f}%) - No Face: {no_face_count}"
            sys.stdout.write(f"\r{progress}")
            sys.stdout.flush()

    print(f"\nProcessed data saved to: {output_dir}")
    print(f"No face detected images saved to: {no_face_dir}")
    print(f"Total images: {total_images}, No face detected: {no_face_count}")

def blur_background(image, face_box, target_size):
    x1, y1, x2, y2 = face_box
    face = image[max(0, y1):min(y2, image.shape[0]), max(0, x1):min(x2, image.shape[1])]
    blurred_image = cv2.GaussianBlur(image, (51, 51), 0)
    blurred_image[max(0, y1):min(y2, image.shape[0]), max(0, x1):min(x2, image.shape[1])] = face
    return cv2.resize(blurred_image, target_size)

def augment_data(input_dir, output_log_dir, target_count=200):
    os.makedirs(output_log_dir, exist_ok=True)

    class_dirs = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d)) and d != "~logs"]
    total_classes = len(class_dirs)
    max_class_name_len = max(len(name) for name in class_dirs)

    for class_idx, class_name in enumerate(class_dirs, start=1):
        class_path = os.path.join(input_dir, class_name)
        images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.lower().endswith(('jpg', 'jpeg', 'png'))]

        if not images:
            print(f"Warning: No images found in class '{class_name}'. Skipping this class.")
            continue

        num_existing = len(images)
        num_to_generate = target_count - num_existing

        generated = 0
        count = 1

        log_file_path = os.path.join(output_log_dir, f"{class_name}_log.txt")
        with open(log_file_path, "w") as log_file:
            log_file.write("Augmentation Details:\n")

            while generated < num_to_generate:
                img_path = random.choice(images)
                img = cv2.imread(img_path)

                # 拡張パラメータをランダム設定
                rotation_range = random.choices([(-20, -5), (5, 45)], weights=[0.4, 0.6])[0]
                rotation = round(random.uniform(*rotation_range), 2)

                shear_range = random.choices([(-0.25, -0.05), (0.05, 0.25)], weights=[0.5, 0.5])[0]
                shear = round(random.uniform(*shear_range), 2)

                flip = random.choices([True, False], weights=[0.35, 0.65])[0]

                # 拡張を手動適用
                transform_parameters = {
                    'theta': rotation,             # 回転
                    'shear': shear,                # シアー
                    'flip_horizontal': flip        # 左右反転
                }
                datagen = ImageDataGenerator()
                augmented_img = datagen.apply_transform(img, transform_parameters)

                save_name = f"aug_{str(count).zfill(3)}_{os.path.basename(img_path)}"
                save_path = os.path.join(class_path, save_name)
                cv2.imwrite(save_path, augmented_img)

                log_file.write(f"{save_name:<22} rotation={rotation:>6.2f}, shear={shear:>6.2f}, flip={flip}\n")

                generated += 1
                count += 1

                sys.stdout.write(f"\rClass {class_idx}/{total_classes}: '{class_name:<{max_class_name_len}}' - {generated}/{num_to_generate}  Total images: {num_existing + generated} (Target: {target_count})")
                sys.stdout.flush()

            print()

if __name__ == "__main__":
    base_dir = os.path.dirname(os.path.abspath(__file__))

    input_dir = os.path.join(base_dir, "dataset")
    processed_dir = os.path.join(base_dir, "processed_data")
    no_face_dir = os.path.join(base_dir, "no_face_data")
    log_dir = os.path.join(processed_dir, "~logs")

    confirm_and_reset_output_dir(processed_dir)
    organize_and_resize_with_blurred_background(input_dir, processed_dir, no_face_dir, target_size=(224, 224))
    augment_data(processed_dir, log_dir, target_count=200)
