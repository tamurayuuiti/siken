import os
import cv2
import numpy as np
import sys
import shutil
import random
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def confirm_and_reset_output_dir(output_dir):
    if os.path.exists(output_dir) and os.listdir(output_dir):
        while True:  # 無効な入力に対して再入力を求める
            response = input(f"Warning: '{output_dir}' already exists and contains data. Do you want to reset it? (yes/no): ").strip().lower()
            if response in ['yes', 'y']:
                print("Resetting processed_data folder...")
                shutil.rmtree(output_dir)
                os.makedirs(output_dir, exist_ok=True)
                break
            elif response in ['no', 'n']:
                print("Aborting process.")
                sys.exit(0)
            else:
                print("Invalid input. Please enter 'yes' or 'no'.")

    else:
        os.makedirs(output_dir, exist_ok=True)

def organize_and_resize_with_blurred_background(input_dir, output_dir, no_face_dir, target_size=(112, 112)):
    cascades_dir = os.path.join(os.path.dirname(__file__), "cascades")
    model_file = os.path.join(cascades_dir, "deploy.prototxt")
    weights_file = os.path.join(cascades_dir, "res10_300x300_ssd_iter_140000.caffemodel")
    net = cv2.dnn.readNetFromCaffe(model_file, weights_file)

    os.makedirs(no_face_dir, exist_ok=True)

    total_images = sum(len(files) for _, _, files in os.walk(input_dir))
    processed_images = 0
    no_face_count = 0

    for class_name in os.listdir(input_dir):
        class_path = os.path.join(input_dir, class_name)
        if not os.path.isdir(class_path):
            continue

        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path)

            if img is None:
                print(f"Warning: Unable to read image {img_path}")
                continue

            (h, w) = img.shape[:2]
            blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
            net.setInput(blob)
            detections = net.forward()

            max_area = 0
            face_box = None
            for i in range(detections.shape[2]):
                confidence = detections[0, 0, i, 2]
                if confidence > 0.5:
                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                    (x1, y1, x2, y2) = box.astype("int")
                    area = (x2 - x1) * (y2 - y1)
                    if area > max_area:
                        max_area = area
                        face_box = (x1, y1, x2, y2)

            if face_box is not None:
                processed_img = blur_background(img, face_box, target_size)
                output_path = os.path.join(output_class_path, img_name)
                cv2.imwrite(output_path, processed_img)
            else:
                no_face_count += 1
                no_face_path = os.path.join(no_face_dir, img_name)
                cv2.imwrite(no_face_path, img)

            processed_images += 1
            progress = f"Processing: {processed_images}/{total_images} ({(processed_images / total_images) * 100:.2f}%) - No Face: {no_face_count}"
            sys.stdout.write(f"\r{progress}")
            sys.stdout.flush()

    print(f"\nProcessed data saved to: {output_dir}")
    print(f"No face detected images saved to: {no_face_dir}")
    print(f"Total images: {total_images}, No face detected: {no_face_count}")

def blur_background(image, face_box, target_size):
    x1, y1, x2, y2 = face_box
    face = image[max(0, y1):min(y2, image.shape[0]), max(0, x1):min(x2, image.shape[1])]
    blurred_image = cv2.GaussianBlur(image, (51, 51), 0)
    blurred_image[max(0, y1):min(y2, image.shape[0]), max(0, x1):min(x2, image.shape[1])] = face
    return cv2.resize(blurred_image, target_size)

def augment_data(input_dir, target_count=200):
    datagen = ImageDataGenerator(
        rotation_range=random.uniform(-15, 40),      # 回転範囲: -15° ～ +40°
        width_shift_range=random.uniform(-0.1, 0.2), # 水平シフト: -10% ～ +20%
        height_shift_range=random.uniform(-0.1, 0.2),# 垂直シフト: -10% ～ +20%
        shear_range=random.uniform(-0.1, 0.2),       # シアー: -10% ～ +20%
        zoom_range=random.uniform(0.1, 0.2),         # ズーム: +10% ～ +20%
        horizontal_flip=True,                        # 左右反転: 50% の確率
        fill_mode='nearest'                          # 隙間を埋める方法
    )

    class_dirs = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d))]
    total_classes = len(class_dirs)

    for class_idx, class_name in enumerate(class_dirs, start=1):
        class_path = os.path.join(input_dir, class_name)
        images = [os.path.join(class_path, img) for img in os.listdir(class_path)]
        num_existing = len(images)
        num_to_generate = target_count - num_existing

        generated = 0
        count = 1

        while generated < num_to_generate:
            img_path = random.choice(images)
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = img.astype('float32') / 255.0
            img = np.expand_dims(img, axis=0)

            augmented_img = next(datagen.flow(img, batch_size=1))[0]
            augmented_img = (augmented_img * 255).astype(np.uint8)
            augmented_img = cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR)

            save_name = f"aug_{str(count).zfill(3)}_{os.path.basename(img_path)}"
            save_path = os.path.join(class_path, save_name)
            cv2.imwrite(save_path, augmented_img)

            generated += 1
            count += 1
            progress = f"Generating: {generated}/{num_to_generate}"
            sys.stdout.write(f"\r{progress}")
            sys.stdout.flush()

        print(f"\nClass {class_idx}/{total_classes}: '{class_name}' - Total images: {len(os.listdir(class_path))} (Target: {target_count})")

if __name__ == "__main__":
    base_dir = os.path.dirname(os.path.abspath(__file__))

    input_dir = os.path.join(base_dir, "dataset")
    processed_dir = os.path.join(base_dir, "processed_data")
    no_face_dir = os.path.join(base_dir, "no_face_data")

    confirm_and_reset_output_dir(processed_dir)
    organize_and_resize_with_blurred_background(input_dir, processed_dir, no_face_dir, target_size=(112, 112))
    augment_data(processed_dir, target_count=200)
