import os
import sys
import time  # クラスごとの処理時間を計測
import cv2
import numpy as np
import insightface
from tqdm import tqdm  # 進捗バーライブラリ
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Input, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input

# ---------------------------------------------
# パス設定と初期化
# ---------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_DIR = os.path.join(BASE_DIR, "processed_data")  # 学習データフォルダ
EMBEDDING_DIR = os.path.join(BASE_DIR, "embeddings")  # 埋め込みベクトル保存フォルダ
MODEL_DIR = os.path.join(BASE_DIR, "model")  # 学習済みモデル保存フォルダ
NO_FACE_DIR = os.path.join(BASE_DIR, "unnecessary_file/no_face_detected")  # 顔が検出できなかった画像の保存先

if not os.path.exists(EMBEDDING_DIR):
    os.makedirs(EMBEDDING_DIR)
if not os.path.exists(MODEL_DIR):
    os.makedirs(MODEL_DIR)
if not os.path.exists(NO_FACE_DIR):
    os.makedirs(NO_FACE_DIR)

# ---------------------------------------------
# ArcFaceモデルの準備
# ---------------------------------------------
print("Loading ArcFace model...")
try:
    app = insightface.app.FaceAnalysis(name='buffalo_l')  # InsightFaceの事前学習済みモデル
    app.prepare(ctx_id=0, det_size=(224, 224))  # GPUを使用（ctx_id=0）
except Exception as e:
    print("GPU not available, switching to CPU...")
    app = insightface.app.FaceAnalysis(name='buffalo_l')
    app.prepare(ctx_id=-1, det_size=(224, 224))  # CPUを使用（ctx_id=-1）

# ---------------------------------------------
# 顔埋め込みベクトルの抽出
# ---------------------------------------------
def extract_face_embeddings(image_path):
    """
    ArcFaceを使用して画像から顔埋め込みベクトルを取得する。
    :param image_path: 画像のパス
    :return: 顔の埋め込みベクトル（またはNone）, 画像
    """
    img = cv2.imread(image_path)
    if img is None:
        return None, img
    
    faces = app.get(img)  # 顔検出と顔埋め込みベクトルの取得
    if len(faces) == 0:
        return None, img
    
    return faces[0].embedding, img  # 最初に検出された顔の埋め込みベクトル

# ---------------------------------------------
# EfficientNetB0による特徴量抽出
# ---------------------------------------------
def extract_efficientnet_features(image):
    """
    EfficientNetB0で画像から特徴量を抽出する
    :param image: OpenCV形式の画像
    :return: EfficientNetB0からの特徴ベクトル
    """
    image_resized = cv2.resize(image, (224, 224))  # EfficientNetB0の入力サイズ
    image_resized = np.expand_dims(image_resized, axis=0)
    image_resized = preprocess_input(image_resized)  # 前処理
    features = efficientnet_model.predict(image_resized)
    return features.flatten()

# ---------------------------------------------
# データセットの処理（埋め込みベクトルの生成）
# ---------------------------------------------
def generate_embeddings(dataset_dir, embedding_save_path):
    """
    データセットの各画像から埋め込みベクトルを生成し保存する。
    :param dataset_dir: データセットフォルダのパス（クラスごとにフォルダ分け）
    :param embedding_save_path: 保存先のパス
    """
    embeddings = []
    labels = []
    class_indices = {}

    total_files = sum(len(files) for _, _, files in os.walk(dataset_dir))  # 総ファイル数
    processed_files = 0

    for class_idx, class_name in enumerate(sorted(os.listdir(dataset_dir))):
        class_path = os.path.join(dataset_dir, class_name)
        if not os.path.isdir(class_path) or class_name in ["no_face_data", "~logs"]:
            continue  # 不要なフォルダを除外
        class_indices[class_idx] = class_name  # クラス名をそのまま使用
        print(f"\nProcessing class '{class_name}'...")

        class_files = [img_name for img_name in os.listdir(class_path) if img_name.lower().endswith(('jpg', 'jpeg', 'png'))]
        no_face_count = 0  # 顔が検出されなかった画像のカウント

        # クラスごとの処理時間を計測
        start_time = time.time()

        for idx, img_name in enumerate(class_files, start=1):
            img_path = os.path.join(class_path, img_name)
            embedding, img = extract_face_embeddings(img_path)
            if embedding is not None:
                efficientnet_features = extract_efficientnet_features(img)
                combined_features = np.concatenate((embedding, efficientnet_features))
                embeddings.append(combined_features)
                labels.append(class_idx)
            else:
                no_face_count += 1
                save_path = os.path.join(NO_FACE_DIR, f"{class_name}_{img_name}")
                if img is not None:
                    cv2.imwrite(save_path, img)

            processed_files += 1
            progress = (processed_files / total_files) * 100
            sys.stdout.write(f"\rClass '{class_name}': {idx}/{len(class_files)} images processed | No face: {no_face_count} | Total Progress: {progress:.2f}%")
            sys.stdout.flush()

        end_time = time.time()
        elapsed_time = end_time - start_time
        print(f"\nClass '{class_name}' completed in {elapsed_time:.2f} seconds | No face detected: {no_face_count}")

    np.savez(embedding_save_path, embeddings=np.array(embeddings), labels=np.array(labels))
    print(f"Embeddings and labels saved to {embedding_save_path}")
    return class_indices

# ---------------------------------------------
# EfficientNetB0モデルの準備
# ---------------------------------------------
efficientnet_base = EfficientNetB0(weights='imagenet', include_top=False, pooling='avg')
input_tensor = Input(shape=(224, 224, 3))
efficientnet_model = Model(inputs=input_tensor, outputs=efficientnet_base(input_tensor))

# ---------------------------------------------
# 分類モデルの構築
# ---------------------------------------------
def build_classification_model(input_dim, num_classes):
    model = Sequential([
        Input(shape=(input_dim,)),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer=Adam(learning_rate=0.00005),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# ---------------------------------------------
# メイン処理
# ---------------------------------------------
if __name__ == "__main__":
    embedding_file = os.path.join(EMBEDDING_DIR, "face_embeddings.npz")
    class_indices = generate_embeddings(DATASET_DIR, embedding_file)

    data = np.load(embedding_file)
    X = data['embeddings']
    y = data['labels']
    y = to_categorical(y, num_classes=len(class_indices))

    print("Building and training classification model...")
    model = build_classification_model(input_dim=X.shape[1], num_classes=len(class_indices))
    model.fit(X, y, validation_split=0.2, epochs=30, batch_size=32)

    model_path = os.path.join(MODEL_DIR, "arcface_efficientnet_model.h5")
    model.save(model_path)
    print(f"Model saved to {model_path}")
