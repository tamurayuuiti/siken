import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.regularizers import l2
import random

# ANSIエスケープコードで色を指定
GREEN = '\033[92m'
RED = '\033[91m'
RESET = '\033[0m'

# ベースディレクトリをスクリプトのディレクトリに設定
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# 各フォルダのパスを動的に設定
CASCADE_DIR = os.path.join(BASE_DIR, "project", "cascades")
DATASET_DIR = os.path.join(BASE_DIR, "project", "dataset")
PROCESSED_DIR = os.path.join(BASE_DIR, "project", "processed_dataset")
NO_FACE_DIR = os.path.join(BASE_DIR, "project", "no_faces_detected")
UNSUPPORTED_FORMAT_DIR = os.path.join(BASE_DIR, "project", "unsupported_format")
AUGMENTED_DIR = os.path.join(BASE_DIR, "project", "augmented_dataset")
MODEL_DIR = os.path.join(BASE_DIR, "project", "model")
RANDOM_FACES_DIR = os.path.join(BASE_DIR, "project", "random_faces")

# ランダム顔画像データセットの準備（背景ノイズ除去）
def prepare_random_faces_with_bbox(target_count):
    """
    必要なランダム顔画像を選択し、list_bbox_celeba.txtを用いて顔領域のみを切り抜いて保存。
    """
    # CelebAの画像フォルダとバウンディングボックスファイル
    celebA_dir = os.path.join(BASE_DIR, "celebA", "img_align_celeba")
    bbox_file = os.path.join(BASE_DIR, "celebA", "list_bbox_celeba.txt")
    
    if not os.path.exists(RANDOM_FACES_DIR):
        os.makedirs(RANDOM_FACES_DIR)
    
    # バウンディングボックス情報を読み込む
    bbox_dict = {}
    with open(bbox_file, "r") as f:
        lines = f.readlines()[2:]  # ヘッダー部分をスキップ
        for line in lines:
            parts = line.strip().split()
            img_name = parts[0]
            x, y, w, h = map(int, parts[1:])
            bbox_dict[img_name] = (x, y, w, h)
    
    # ランダムサンプリングで指定枚数を取得
    all_images = os.listdir(celebA_dir)
    selected_images = random.sample(all_images, target_count)
    
    for img_name in selected_images:
        src_path = os.path.join(celebA_dir, img_name)
        dest_path = os.path.join(RANDOM_FACES_DIR, img_name)
        if img_name in bbox_dict:
            x, y, w, h = bbox_dict[img_name]
            img = cv2.imread(src_path)
            if img is not None:
                # 顔領域を切り抜き
                face = img[y:y+h, x:x+w]
                face_resized = cv2.resize(face, (224, 224))  # サイズを統一
                cv2.imwrite(dest_path, face_resized)
    print(f"Random faces prepared with bounding boxes: {target_count} images.")

# 顔検出用関数
def detect_face_dnn(image_path, target_size=(224, 224), confidence_threshold=0.5):
    model_file = os.path.join(CASCADE_DIR, "res10_300x300_ssd_iter_140000.caffemodel")
    config_file = os.path.join(CASCADE_DIR, "deploy.prototxt")
    
    net = cv2.dnn.readNetFromCaffe(config_file, model_file)
    img = cv2.imread(image_path)
    
    if img is None:
        print(f"Error: Failed to load image at {image_path}")
        return None
    
    h, w = img.shape[:2]
    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
    net.setInput(blob)
    detections = net.forward()
    
    best_face = None
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > confidence_threshold:
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (x1, y1, x2, y2) = box.astype("int")
            face = img[y1:y2, x1:x2]
            if best_face is None or face.shape[0] * face.shape[1] > best_face.shape[0] * best_face.shape[1]:
                best_face = face
    
    if best_face is None:
        print(RED + f"No face detected in {image_path}. Skipping this image." + RESET)
        return None
    else:
        print(GREEN + f"Face detected in {image_path}." + RESET)
    
    return cv2.resize(best_face, target_size)

# 学習用画像の保存（顔が検出された画像のみ）
def preprocess_images(input_dir, output_dir, no_face_dir, unsupported_format_dir):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    if not os.path.exists(no_face_dir):
        os.makedirs(no_face_dir)
    if not os.path.exists(unsupported_format_dir):
        os.makedirs(unsupported_format_dir)
    
    for class_dir in os.listdir(input_dir):
        class_path = os.path.join(input_dir, class_dir)
        output_class_path = os.path.join(output_dir, class_dir)
        
        if not os.path.exists(output_class_path):
            os.makedirs(output_class_path)
        
        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            try:
                img = cv2.imread(img_path)
                if img is None:
                    unsupported_img_path = os.path.join(unsupported_format_dir, img_name)
                    cv2.imwrite(unsupported_img_path, cv2.imread(img_path))
                    print(RED + f"Unsupported format: {img_path}. Moved to {unsupported_img_path}" + RESET)
                    continue

                face_img = detect_face_dnn(img_path)
                if face_img is not None:
                    output_img_path = os.path.join(output_class_path, img_name)
                    cv2.imwrite(output_img_path, face_img)
                    print(f"Image saved successfully: {output_img_path}")
                else:
                    no_face_img_path = os.path.join(no_face_dir, img_name)
                    cv2.imwrite(no_face_img_path, img)
                    print(f"No face detected. Image moved to {no_face_img_path}")
            except Exception as e:
                print(RED + f"Error processing {img_path}: {e}" + RESET)

# データ拡張を実行して保存
def augment_and_save_images(dataset_dir, target_dir, target_count=200):
    datagen = ImageDataGenerator(
        rotation_range=30,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    for class_dir in os.listdir(dataset_dir):
        class_path = os.path.join(dataset_dir, class_dir)
        output_class_path = os.path.join(target_dir, class_dir)
        
        if not os.path.exists(output_class_path):
            os.makedirs(output_class_path)
        
        images = [os.path.join(class_path, img_name) for img_name in os.listdir(class_path)]
        num_existing = len(images)
        num_to_generate = target_count - num_existing
        
        if num_to_generate > 0:
            print(GREEN + f"Augmenting {num_to_generate} images for class '{class_dir}'." + RESET)
            for img_path in images:
                img = cv2.imread(img_path)
                if img is None:
                    continue
                img = cv2.resize(img, (224, 224))
                img = img.astype('float32') / 255.0
                img = np.expand_dims(img, axis=0)
                generated = 0
                for batch in datagen.flow(img, batch_size=1, save_to_dir=output_class_path, save_prefix='aug', save_format='jpeg'):
                    generated += 1
                    if generated >= num_to_generate:
                        break

# データセット前処理
preprocess_images(DATASET_DIR, PROCESSED_DIR, NO_FACE_DIR, UNSUPPORTED_FORMAT_DIR)

# データ拡張（目標: 各クラス200枚）
augment_and_save_images(PROCESSED_DIR, AUGMENTED_DIR, target_count=200)

# EfficientNetB0をベースモデルとしてロード
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in base_model.layers[:-12]:
    layer.trainable = False

# 全結合層の簡略化
model = Sequential([
    base_model,
    Flatten(),
    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),
    Dropout(0.5),
    Dense(8, activation='softmax')
])

# クラス名の設定をフォルダ名から取得
custom_classes = sorted([d for d in os.listdir(AUGMENTED_DIR) if os.path.isdir(os.path.join(AUGMENTED_DIR, d))])

# データ拡張の調整
datagen = ImageDataGenerator(
    validation_split=0.2
)

# データジェネレータ
train_generator = datagen.flow_from_directory(
    AUGMENTED_DIR,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    classes=custom_classes,
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    AUGMENTED_DIR,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    classes=custom_classes,
    subset='validation'
)

# ReduceLROnPlateauとEarlyStoppingの設定
lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=0.00001)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
optimizer = Adam(learning_rate=0.0001)

# モデルのコンパイル
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# モデルの学習
history = model.fit(
    train_generator,
    epochs=60,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    callbacks=[lr_reduction, early_stopping]
)

# モデルの保存
def save_model(model, save_dir, filename):
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    model_path = os.path.join(save_dir, filename)
    model.save(model_path)
    print(f"Model saved successfully: {model_path}")

save_model(model, MODEL_DIR, 'efficientnet_finetuned_face_recognition_model_augmented.keras')
