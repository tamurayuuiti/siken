import os
import cv2
import numpy as np
import imagehash
from PIL import Image
from itertools import combinations
import statistics
import shutil

def calculate_phash(image_path):
    """
    画像からPHashを計算する関数。
    """
    try:
        img = Image.open(image_path)
        return imagehash.phash(img)
    except Exception as e:
        print(f"Error processing {image_path}: {e}")
        return None

def compare_images_by_hash(image_paths):
    """
    画像のハッシュ値を計算し、画像間の類似度を判定する関数。
    ハミング距離を使用して類似度を評価。
    """
    hash_dict = {}
    for img_path in image_paths:
        img_hash = calculate_phash(img_path)
        if img_hash is not None:
            hash_dict[img_path] = img_hash
    return hash_dict

def calculate_similarity(hash_dict):
    """
    ハッシュ値の差分（ハミング距離）を基に画像間の類似度を計算する関数。
    """
    similarity_results = []
    for (img1, hash1), (img2, hash2) in combinations(hash_dict.items(), 2):
        distance = hash1 - hash2  # ハミング距離
        similarity_results.append((img1, img2, distance))
    return similarity_results

def save_similarity_logs(log_dir, class_name, similarity_results):
    """
    類似度の結果をログファイルに保存する関数。
    """
    os.makedirs(log_dir, exist_ok=True)
    log_file_path = os.path.join(log_dir, f"{class_name}_similarity_log.txt")
    with open(log_file_path, "w") as log_file:
        log_file.write("Image1\t\t\tImage2\t\t\tHamming Distance\n")
        for img1, img2, distance in similarity_results:
            log_file.write(f"{os.path.basename(img1)}\t{os.path.basename(img2)}\t{distance}\n")

def calculate_statistics(similarity_results):
    """
    ハミング距離の統計指標を計算する関数。
    """
    distances = [distance for _, _, distance in similarity_results]
    if distances:
        mean = statistics.mean(distances)
        std_dev = statistics.stdev(distances) if len(distances) > 1 else 0
        min_value = min(distances)
        max_value = max(distances)
    else:
        mean = std_dev = min_value = max_value = 0
    return mean, std_dev, min_value, max_value

def find_similar_images(hash_dict, threshold=5):
    """
    画像間のハッシュ値を比較し、類似度が閾値以下の画像ペアを検出する関数。
    """
    similar_images = []
    for (img1, hash1), (img2, hash2) in combinations(hash_dict.items(), 2):
        distance = hash1 - hash2
        if distance <= threshold:
            similar_images.append((img1, img2, distance))
    return similar_images

def remove_similar_images(log_file, similar_images, removed_image_dir, class_name):
    """
    重複画像を削除し、削除した情報をログに記録する関数。
    削除した画像は指定ディレクトリに保存し、名前を変更する。
    """
    os.makedirs(removed_image_dir, exist_ok=True)
    removed_images = set()
    count = 1

    for img1, img2, distance in similar_images:
        if img2 not in removed_images:
            try:
                # 新しい名前を生成して画像を移動
                new_name_1 = f"{class_name}_{str(count).zfill(3)}_1{os.path.splitext(img1)[1]}"
                new_name_2 = f"{class_name}_{str(count).zfill(3)}_2{os.path.splitext(img2)[1]}"
                shutil.copy(img1, os.path.join(removed_image_dir, new_name_1))
                shutil.move(img2, os.path.join(removed_image_dir, new_name_2))
                
                # 削除した画像を記録
                log_file.write(f"{class_name}\t{os.path.basename(img1)}\t{os.path.basename(img2)}\t{distance}\n")
                print(f"Removed: {img2} -> Saved as {new_name_2} (similar to {img1})")
                removed_images.add(img2)
                count += 1
            except Exception as e:
                print(f"Error handling {img2}: {e}")

def process_data(processed_data_dir, log_dir, threshold=5):
    """
    processed_data内の各クラスの画像についてハッシュベースの類似度を計算し、ログに保存し、
    類似画像を検出・削除する関数。
    """
    if not os.path.exists(processed_data_dir):
        print(f"Error: '{processed_data_dir}' does not exist.")
        return

    # ディレクトリ作成
    similarity_log_dir = os.path.join(log_dir, "similarity_log")
    removed_log_dir = os.path.join(log_dir, "removed_log")
    removed_image_dir = os.path.join(removed_log_dir, "images")
    removal_log_path = os.path.join(removed_log_dir, "removed_images_log.txt")
    os.makedirs(similarity_log_dir, exist_ok=True)
    os.makedirs(removed_log_dir, exist_ok=True)

    summary_stats = []

    class_dirs = [d for d in os.listdir(processed_data_dir) if os.path.isdir(os.path.join(processed_data_dir, d))]

    with open(removal_log_path, "w") as removal_log_file:
        removal_log_file.write("Class Name\tImage1\t\t\tImage2\t\t\tHamming Distance\n")

        for class_name in class_dirs:
            class_path = os.path.join(processed_data_dir, class_name)
            print(f"Processing class: {class_name}")

            # クラス内の画像パスを取得
            image_paths = [os.path.join(class_path, img) for img in os.listdir(class_path)
                           if img.lower().endswith(('jpg', 'jpeg', 'png'))]

            if len(image_paths) < 2:
                print(f"Warning: Not enough images in class '{class_name}' for comparison.")
                continue

            # ハッシュ計算
            hash_dict = compare_images_by_hash(image_paths)

            # 類似度の結果を計算
            similarity_results = calculate_similarity(hash_dict)
            save_similarity_logs(similarity_log_dir, class_name, similarity_results)

            # 統計指標を計算
            mean, std_dev, min_value, max_value = calculate_statistics(similarity_results)
            summary_stats.append((class_name, mean, std_dev, min_value, max_value))

            # 類似画像の検出と削除
            similar_images = find_similar_images(hash_dict, threshold)
            remove_similar_images(removal_log_file, similar_images, removed_image_dir, class_name)

            print(f"Finished processing class: {class_name}")

    save_summary_statistics(summary_stats, similarity_log_dir)
    print("Summary statistics and similarity logs saved.")

def save_summary_statistics(summary_stats, log_dir):
    """
    全クラスの統計情報をまとめて保存する関数。
    """
    summary_file_path = os.path.join(log_dir, "summary_statistics.txt")
    with open(summary_file_path, "w") as summary_file:
        summary_file.write("Class Name\tMean\t\tStandard Deviation\tMin\tMax\n")
        for class_name, mean, std_dev, min_value, max_value in summary_stats:
            summary_file.write(f"{class_name:<12}\t{mean:.2f}\t\t{std_dev:.2f}\t\t\t{min_value}\t{max_value}\n")

if __name__ == "__main__":
    # ディレクトリ設定
    base_dir = os.path.dirname(os.path.abspath(__file__))
    processed_data_dir = os.path.join(base_dir, "processed_data")
    log_dir = os.path.join(base_dir, "logs")

    # 閾値設定
    threshold = 5

    # データ処理
    process_data(processed_data_dir, log_dir, threshold)
    print("Data processing completed. Logs and statistics are saved.")
