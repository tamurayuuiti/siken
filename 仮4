import os
import cv2
import numpy as np
import insightface
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
import tensorflow as tf
import time  # 処理時間計測用

# ---------------------------------------------
# パス設定と初期化
# ---------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TEST_VIDEOS_DIR = os.path.join(BASE_DIR, "test_videos")
RESULT_VIDEOS_DIR = os.path.join(BASE_DIR, "results_videos")
NO_FACE_VIDEOS_DIR = os.path.join(BASE_DIR, "unnecessary_file/test_no_face_detected")
DATASET_DIR = os.path.join(BASE_DIR, "processed_data")
MODEL_DIR = os.path.join(BASE_DIR, "main_model")
MODEL_PATH = os.path.join(MODEL_DIR, "combined_model_saved")  # TensorFlow SavedModel形式のパス

if not os.path.exists(RESULT_VIDEOS_DIR):
    os.makedirs(RESULT_VIDEOS_DIR)
if not os.path.exists(NO_FACE_VIDEOS_DIR):
    os.makedirs(NO_FACE_VIDEOS_DIR)

# ArcFaceとEfficientNetB0の読み込み
print("Loading ArcFace model...")
app = insightface.app.FaceAnalysis(name='buffalo_l')
app.prepare(ctx_id=-1, det_size=(224, 224))

print("Loading EfficientNetB0 model for feature extraction...")
base_efficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_efficientnet.output
efficientnet_output = tf.keras.layers.GlobalAveragePooling2D()(x)
efficientnet_model = Model(inputs=base_efficientnet.input, outputs=efficientnet_output)

print("Loading trained model...")
model = tf.keras.models.load_model(MODEL_PATH)  # TensorFlow SavedModel形式でロード

import json
class_indices_path = os.path.join(MODEL_DIR, "class_indices.json")
with open(class_indices_path, "r") as f:
    class_indices = json.load(f)
class_names = [class_indices[str(i)] for i in range(len(class_indices))]
print(f"Loaded class names: {class_names}")

# ---------------------------------------------
# 画像の前処理関数
# ---------------------------------------------
def extract_embeddings(image, face):
    try:
        arcface_embedding = face.embedding
        x1, y1, x2, y2 = face.bbox.astype(int)
        h, w, _ = image.shape
        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)
        face_img = image[y1:y2, x1:x2]
        if face_img.size == 0:
            return None, None
        face_resized = cv2.resize(face_img, (224, 224))
        face_array = np.expand_dims(face_resized / 255.0, axis=0)
        efficientnet_embedding = efficientnet_model.predict(face_array, verbose=0).flatten()
        return arcface_embedding, efficientnet_embedding
    except Exception as e:
        print(f"Error during embedding extraction: {e}")
        return None, None

# ---------------------------------------------
# 動画の推論処理
# ---------------------------------------------
print("Starting inference on test videos...")
UNKNOWN_THRESHOLD = 80.0
MIN_FONT_SCALE = 0.8
MAX_FONT_SCALE = 3.5

for video_name in os.listdir(TEST_VIDEOS_DIR):
    test_video_path = os.path.join(TEST_VIDEOS_DIR, video_name)
    cap = cv2.VideoCapture(test_video_path)
    if not cap.isOpened():
        print(f"Unable to open video: {test_video_path}")
        continue

    # 結果動画の保存先
    result_video_path = os.path.join(RESULT_VIDEOS_DIR, f"result_{video_name}")
    fourcc = cv2.VideoWriter_fourcc(*'XVID')
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # 総フレーム数
    out = cv2.VideoWriter(result_video_path, fourcc, fps, (frame_width, frame_height))

    no_face_detected = True
    frame_idx = 0
    start_time = time.time()  # 処理開始時間を記録

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        faces = app.get(frame)
        if len(faces) > 0:
            no_face_detected = False

        for face_idx, face in enumerate(faces, start=1):
            arcface_embedding, efficientnet_embedding = extract_embeddings(frame, face)
            if arcface_embedding is None or efficientnet_embedding is None:
                continue

            embeddings_input = [np.expand_dims(arcface_embedding, axis=0), np.expand_dims(efficientnet_embedding, axis=0)]
            predictions = model.predict(embeddings_input, verbose=0)

            predicted_class_index = np.argmax(predictions)
            confidence = predictions[0][predicted_class_index] * 100

            # 修正: unknownの場合の確率を「100% - 一番高いクラスの確率」に設定
            if confidence < UNKNOWN_THRESHOLD:
                predicted_class = "unknown"
                confidence = 100.0 - confidence  # 100%から最も高いクラスの確率を引く
            else:
                predicted_class = class_names[predicted_class_index]

            x1, y1, x2, y2 = face.bbox.astype(int)
            label = f"{predicted_class} ({confidence:.2f}%)"
            color = (0, 255, 0) if predicted_class != "unknown" else (0, 0, 255)
            font_scale = max(frame_width, frame_height) / 1200
            font_scale = max(MIN_FONT_SCALE, min(MAX_FONT_SCALE, font_scale))
            thickness = max(1, int(font_scale * 2))

            cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)
            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)

        out.write(frame)  # 結果フレームを保存
        frame_idx += 1

        # 進捗状況をリアルタイムで表示
        elapsed_time = time.time() - start_time
        progress = (frame_idx / total_frames) * 100
        print(f"Processing {video_name}: {frame_idx}/{total_frames} frames ({progress:.2f}%) - Elapsed Time: {elapsed_time:.2f}s", end="\r")

    cap.release()
    out.release()

    if no_face_detected:
        no_face_video_path = os.path.join(NO_FACE_VIDEOS_DIR, video_name)
        shutil.move(test_video_path, no_face_video_path)
        print(f"\nNo faces detected. Moved video to: {no_face_video_path}")
    else:
        print(f"\nResults saved to: {result_video_path}")
